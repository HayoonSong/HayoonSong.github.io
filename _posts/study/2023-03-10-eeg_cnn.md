---
layout: post
title: '[EEG] CNN 모델을 이용한 EEG 분류'
subtitle: A Convolutional Neural Network for EEG Source
date: '2021-08-10'
categories:
    - study
tags:
    - eeg
    - deep-learning
related_posts: 
comments: true
published: true
last_modified_at: '2021-08-10'
---

뇌파 데이터에서 1D Convolution과 2D Convolution을 사용하는 경우를 알아보고자 합니다.

* this unordered seed list will be replaced by the toc
{:toc}


## Introduction

***

1차원 CNN은 시계열 분석(time-series analysis) 또는 텍스트 분석에서, 2차원 CNN은 이미지 분석에서 주로 사용된다고 알려져 있습니다. '뇌파(EEG)는 시계열 데이터인데 왜 2차원 CNN을 사용하는 것일까?'라는 질문의 답을 찾는 과정을 정리하였습니다. 정답은 뇌파의 경우 EEG channels에 대한 공간 정보를 담고 있으므로 이미지로 봐야 하기 때문입니다.

## 1D Convolution

***  

![Conv1D](https://cdn.jsdelivr.net/gh/HayoonSong/Images-for-Github-Pages/study/eeg/2023-03-10-eeg_cnn/conv1d.png?raw=true)   
1D convolution
{:.figure}

![Conv1D](https://cdn.jsdelivr.net/gh/HayoonSong/Images-for-Github-Pages/study/eeg/2023-03-10-eeg_cnn/conv1d.jpg?raw=true)   
1D convolution
{:.figure}

1차원 CNN은 **한 반향(가로)**으로 이동하면서 합성곱을 계산합니다. 

Tensorflow 와 Pytorch의 input signal shape이 다른데요, tensorflow는 `data_format`이 default로 'channels_last'로 되어있기 때문입니다. 물론, 'data_format' = 'channels_first'로 설정하면 Pytorch와 동일하게 input이 들어갑니다. 그러나, 이후 모든 layer의 'data_format'을 지정해야 하므로 실수를 방지하기 위해 처음부터 input의 shape을 변경해주었습니다. 

`filters`와 `out_channels`는 같은 파리미터로, output으로 내고싶은 dimension의 개수를 나타냅니다. `kernel_size`는 kernel의 길이를 설정하는 파라미터(=filter size)로, time step을 얼마만큼씩 이동할 것인지를 고려해야 합니다. 1차원 CNN을 적용하면 feature map의 길이(length)는 다음과 같이 나옵니다.

$$
Out\, length = \frac{timepoints - kernel\_size + (2 * padding)}{stride} + 1
$$

~~~python
import tensorflow as tf
from tensorflow import keras
import torch
import torch.nn as nn


# Conv1D in Tensorflow
model = keras.Sequential()
model.add(keras.layers.Input(shape=(1000, 1))) # (timepoints, in_channels)
model.add(keras.layers.Conv1D(8, kernel_size=125))
print('Conv1D in Tensorflow'.center(70,'-'))
model.summary()
print('\n')

# Conv1D in Pytorch
signal = torch.rand(128, 1, 1000) # (batch_size, in_channels, timepoints)
conv1d_torch = nn.Conv1d(1, 8, kernel_size=125)
out_torch = conv1d_torch(signal)
print('Conv1D in Pytorch'.center(70,'-'))
print('Input_size:', signal.shape)
print('Kernel_size:', conv1d_torch.weight.shape)
print('Output_size:', out_torch.shape)
~~~

![Conv1D_Reuslt](https://cdn.jsdelivr.net/gh/HayoonSong/Images-for-Github-Pages/study/eeg/2023-03-10-eeg_cnn/result_conv1d.png?raw=true)   
Result of 1D convolution
{:.figure}

Tesorflow는 trainable params에 bias까지 포함해서 보여줍니다.

$$
\begin{align} 
& W_c = kernel\_size \times in\_channels \times out\_channels \\
& B_c = out\_channels \\
& P_c = W_c + B_c
\end{align}
$$

## 2D Convolution

***

2차원 CNN은 **가로, 세로**를 이동하면서 합성곱을 계산합니다. 

Tensorflow에서 `input_shape`을 넣어줄 경우, 이미지는 [batch size, width, height, in_channels]가 되며 EEG는 [batch size, EEG channels, timepoints, 1]이 됩니다. 즉, 흑백의 이미지를 넣는다고 보시면 됩니다. 

2차원 CNN의 `kernel_size`는 kernel의 가로(width), 세로(height)의 길이를 설정하는 파라미터입니다.  

~~~python
import tensorflow as tf
from tensorflow import keras
import torch
import torch.nn as nn

# Conv2D in Tensorflow
model = keras.Sequential()
model.add(keras.layers.Input(shape=(32, 1000, 1))) # (EEG_channels, timepoints, in_channels)
model.add(keras.layers.Conv2D(32, kernel_size=5))
print('Conv2D in Tensorflow'.center(70,'-'))
model.summary()
print('\n')

# Conv2D in Pytorch
signal = torch.rand(128, 1, 32, 1000) # (batch_size, in_channels, EEg_channels, timepoints)
conv2d_torch = nn.Conv2d(1, 32, kernel_size=5)
out_torch = conv2d_torch(signal)
print('Conv2D in Pytorch'.center(70,'-'))
print('Input_size:', signal.shape)
print('Kernel_size:', conv2d_torch.weight.shape)
print('Output_size:', out_torch.shape)
~~~

![Conv2D_Result](https://cdn.jsdelivr.net/gh/HayoonSong/Images-for-Github-Pages/study/eeg/2023-03-10-eeg_cnn/result_conv2d.png?raw=true)   
Result of 2D convolution
{:.figure}

## Summary

***

1차원 CNN은 뇌파의 시계열 분석에 용이하지만 다채널(multi-channel) EEG의 공간적인 정보를 담을 수 없으므로, **뇌파 데이터는 주로 2차원 CNN을 사용**합니다. 다만, Single-channel EEG는 1차원 CNN이 사용됩니다.

## References

***

[1] 뢀뢀이, Conv1D, Conv2D, Conv3D 차이. [[Online]](https://leeejihyun.tistory.com/37) 
[2] 휴석사, 시계열 데이터를 위한 1D convolution과 1x1 convolution. [[Online]](https://sanghyu.tistory.com/24)
[3] joonas, Conv2d 알아보기. [[Online]](https://blog.joonas.io/196?category=1016329) 

<br>

***

<center>오류나 틀린 부분이 있을 경우 언제든지 댓글 혹은 메일로 지적해주시면 감사하겠습니다.</center>