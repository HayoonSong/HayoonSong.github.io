---
layout: post
title: '[Paper Review] Contrastive Representation Learning for Electroencephalogram Classication'
subtitle: SeqCLR
date: '2022-02-03'
categories:
    - study
tags:
    - seqclr
comments: true
pusblished: true

last_modified_at: '2022-02-03'
---

Self-supervised learning

## Overview

***

* Channel Augmenter
    - Time shift
    - Masking
    - Amplitude scale
    - Band-stop filter
    - DC shift
    - Additive noise
    
* Channel Encoder
* Projector
* Contrastive loss function

## Method

***

### Channel recombination and preprocessing

#### Channel augmentations


Transformation Ranges
| Transformation                    | min | max |
|:----------------------------------|:---:|:---:|
| Amplitude scale                   | 0.5 |  2  |
| Time shift (samples)              | -50 | 50  |
| DC shift (µV)                     | -10 | 10  |
| Zero-masking (samples)            |  0  | 150 |
| Additive Gaussian noise (σ)       |  0  | 0.2 |
| Band-stop filter (5 Hz width) (Hz)| 2.8 |82.5 |


## Appendix

***

### A. Choosing the sequence-length

다른 EEG 분류 과제에는 다른 길이의 시퀀스가 필요합니다.
예를 들어, 수면 단계를 분류하기 위해서는 30 이상의 긴 시퀀스가 필요하지만
감정 인식 또는 동작 상상 분류와 같은 과제는 1초 혹은 더 짧은 시퀀스로 정의됩니다.

본 논문에서는 encoder가 다양한 과제에 유용한 특징을 학습할 수 있도록 하기 위해 사전 실험을 진행하였습니다. 다양한 길이의 신호에 대해 encoder를 학습하고 감정 인식 및 수면 단계 분류 정확도를 비교하였습니다.

![Sequence-length](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/study/paper_review/2022-02-03-SimCLR/appendixA.PNG?raw=true)

사전 실험을 통해 20초 길이의 시퀀스가 두 과제 모두에서 잘 수행되는 것이 관찰되었습니다. 