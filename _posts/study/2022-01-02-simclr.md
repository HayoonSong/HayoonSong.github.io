---
layout: post
title: '[Paper Review] A Simple Framework for Contrastive Learning of Visual Representations'
subtitle: SimCLR
date: '2022-02-03'
categories:
    - study
tags:
    - simclr
comments: true
pusblished: true

last_modified_at: '2022-02-03'
---

self-supervised learning

- Table of Contents
{:toc .large-only}

## Overview

***

* Data augmentation module
    - Random cropping and resize to original
    - Random color distortions (jitter or drop)
    - Random Gaussian blur

* Base encoder (Unsupervised pretraining)
    - ResNet-50
    
* Projection head
* Contrastive loss function

## Contrastive learning

> Contrastive learning is a machine learning technique used to learn the **general features** of a dataset **without labels** by teaching the model which data points are similar or different.   
Contrastive learning은 레이블 정보를 사용하지 않는 **비지도 학습**으로 데이터의 **일반적인 특징(general features)**을 학습하기 위해 사용됩니다.

예를 들어, 

![Contrastive learning](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/study/paper_review/2022-02-03-SimCLR/ContrastiveLearning.png?raw=true){: .align-center}


## Method

***

![Simple framework](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/study/paper_review/2022-02-03-SimCLR/Framework.PNG?raw=true){: width="50%" height="50%"}{: .align-center}

### The Contrastive Learning Framework
<br/>

* **Data augmentation module**
    - 하나의 input을 변환하여 두 개의 상관된 보기($x_i$ 및 $x_j$)를 생성하는 확률적 데이터 증강 모듈입니다.
    - Random cropping and resize to original, random color distortions (jitter or drop), random Gaussian blur 순으로 3 가지의 데이터 증강기법을 적용합니다.  
    <br/>
    
    ![Data augmentation final](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/study/paper_review/2022-02-03-SimCLR/data_augmentation_final.jpg?raw=true){: .align-center}

* **Base encoder (Unsupervised pretraining)**
    - 증강된 데이터에서 표현 벡터(repersentation vectors)를 추출하는 신경망 기반 인코더입니다.
    - 이미지 분류에서 일반적으로 사용되는 ResNet-50을 활용하였습니다.
    <br/>
    <br/>

* **Projection head**
    - Map representations to the space where contrastive loss is applied.
    - Use MLP with one hidden layer
    - $ z_i = g(h_i) = W^{(2)}σ(W^{(1)}h_i) $
    - 사전 실험을 통해 $ h_i $보다 $ z_i $에 contrastive loss를 정의하였을 때 더 beneficial한 것을 확인하였습니다.
    <br/>
    <br/>

* **Contrastive loss function**
    - Contrastive prediction task를 위해 정의하였습니다.
    - Positive pair인 $x_i$ 및 $x_j$를 포함하는 세트 {$x_k$}가 주어지면 contrastive task는 주어진 $x_i$에 대해 {$x_k$}$_{k≠i}$에서 $x_j$를 식별하는 것을 목표로 합니다.
    <br/>
    <br/>

미니배치 N에서 파생된 증강 데이터에 대한 쌍을 contastive prediction task로 정의하여 2N 개의 데이터 포인트를 생성합니다. Negative examples을 명시적으로 샘플링하지 않았습니다. 대신 positive pair가 주어지면 미니배치 내의 2(N-1)개의 증강된 데이터를 positive examples로 취급하였습니다. $ sim(υ, ν) = υ^Tν/\Vert υ \Vert \Vert ν \Vert $ 는 $ l_2 $ normalized된 $ υ $ 와 $ ν $ 사이의 내적(즉, 코사인 유사도)을 나타냅니다. Positive pair($ i, j $)에 대한 손실 함수는 다음과 같이 정의됩니다.


$$
l_{i,j} = - \log \frac{\exp(sim(z_i,z_j)/τ)}{\sum_{k=1}^{2N}1_{[k≠i]}\exp(sim(z_i,z_k)/τ)}
$$

$1_{[k≠i]} ∈ \{0, 1\}$는 $k≠i$일 때 $1$로 평가되는 indicator function이며, $τ$는 temperature parameter입니다. 최종 손실은 미니배치서 ($i,j$) 및 ($j,i$)의 모든 positive pairs에 대해 계산됩니다. 이를 NT-Xent (the normalized temperature-scaled cross entropy loss)라고 합니다.

### Training with Large Batch Size


### Data Augmentation for Contrastive Representation Learning

***

데이터 증강의 유형 중에서 가장 좋은 성능을 보이는 방법을 찾기 위한 실험을 진행하였습니다. 개별적인 데이터 증강과 증강 구성의 중요성을 조사하였습니다.

* 공간적/기하학적 변형 (spatial/geometric transformation)
    - Cropping and resizing (with horizontal flipping)
    - Rotation
    - Cutout 

* 모양 변형 (appearance transformation)
    - Color distortion (including color dropping, brightness, contrast, saturation, hue)
    - Gaussian blur
    - Sobel filtering

![Data augmentation](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/study/paper_review/2022-02-03-SimCLR/data_augmentation.png?raw=true){: .align-center}

ImgaeNet 이미지는 크기가 다르기 때문에 데이터 증강 이전에 기본적으로 이미지 자르기 및 크기 조정을 적용하였습니다.  

![Data augmentation confusion matrix](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/study/paper_review/2022-02-03-SimCLR/data_augmentation_cm.PNG?raw=true){: .align-center}


## References
[1] Predictive Intelligence in Medicine: 4th International Workshop, PRIME 2021, Held in Conjunction with MICCAI 2021, Strasbourg, France, October 1, 2021,