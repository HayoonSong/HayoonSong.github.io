---
layout: post
title: '[EEG] Contrastive learning'
subtitle: EEGCLR
date: '2022-02-03'
categories:
    - project
tags:
    - eegclr
comments: true
pusblished: false

last_modified_at: '2022-02-03'
---

self-supervised learning

- Table of Contents
{:toc .large-only}

## Overview

* Augmenter
* Encoder
    - EEGNet
* Projector
* Contrastive loss function

## Method

***

### The Contrastive Learning Framework
<br/>

* **Data augmentation module**
    - 하나의 input을 변환하여 두 개의 상관된 보기($x_i$ 및 $x_j$)를 생성하는 확률적 데이터 증강 모듈입니다.
    -   
    <br/>

* **Base encoder (Unsupervised pretraining)**
    - 증강된 데이터에서 표현 벡터(repersentation vectors)를 추출하는 신경망 기반 인코더입니다.
    - 동작 상상 분류에서 일반적으로 사용되는 EEGNet을 활용하였습니다.
    <br/>
    <br/>

* **Projection head**
    - Map representations to the space where contrastive loss is applied.
    - Use MLP with one hidden layer
    - $ z_i = g(h_i) = W^{(2)}σ(W^{(1)}h_i) $
    <br/>
    <br/>

* **Contrastive loss function**
    - Contrastive prediction task를 위해 정의하였습니다.
    - Positive pair인 $x_i$ 및 $x_j$를 포함하는 세트 {$x_k$}가 주어지면 contrastive task는 주어진 $x_i$에 대해 {$x_k$}$_{k≠i}$에서 $x_j$를 식별하는 것을 목표로 합니다.
    - Projection head의 ouput $ zi $, $ zj $에 $l_2$ normalize를 적용합니다.
    - 
    <br/>
    <br/>

### Data Augmentation for Contrastive Representation Learning

#### Channel augmentations
Transformation Ranges

| Transformation                    | min | max |
|:----------------------------------|:---:|:---:|
| Amplitude scale                   | 
| Time shift (samples)              | 
| DC shift (µV)                     | 
| Zero-masking (samples)            | 
| Additive Gaussian noise (σ )      | 
| Band-stop filter (5 Hz width) (Hz)| 



## Appendix

***

### A. Choosing the length
<br/>

EEG 데이터셋 간의 trial 길이가 다르기에 사전 실험을 통해 모든 데이터셋에서 좋은 성능을 보인 trial 길이를 확인하였습니다.

![Time length](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/project/2022-01-02-eegclr/TimeLength.png?raw=true){: .align-center}

| Time length (second)| Average accuracy (%) |
|:--------------------|----------------------|
| 1                   |         51.8         |  
| 2                   |         56.4         |
| 3                   |       **60.6**       |   

3초의 길이를 사용하였을 때 다섯 가지 데이터셋 모두에서 잘 수행되는 것이 관찰되었습니다.  

### B. Data Augmentation
<br/>

* Amplitude scale

![Amplitude scale](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/project/2022-01-02-eegclr/amplitude_scale.png?raw=true){:.aligncenter}

* Time shift

![Time shift](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/project/2022-01-02-eegclr/time_shift.png?raw=true){: .align-center}

* DC shift

![DC shift](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/project/2022-01-02-eegclr/dc_shift.png?raw=true){: .align-center}

* Masking

![Masking](https://github.com/HayoonSong/Images-for-Github-Pages/blob/main/project/2022-01-02-eegclr/gaussian_noise.png?raw=true){: .align-center}

* Gaussian noise

## Reference
### Softmax
1. https://inhovation97.tistory.com/30#:~:text=softmax%20%ED%95%A8%EC%88%98%EB%8A%94%20cost%20%ED%95%A8%EC%88%98,%EC%97%90%20%2Dlog%EB%A5%BC%20%EC%94%8C%EC%9B%81%EB%8B%88%EB%8B%A4.&text=%EA%B7%B8%EB%9E%98%EC%84%9C%20%2D%EA%B0%92%EC%9D%84%20%EB%84%A3%EC%96%B4%EC%A3%BC%EA%B3%A0,%EC%89%BD%EA%B2%8C%20%EC%B5%9C%EB%8C%80%ED%99%94%20%EC%8B%9C%ED%82%A4%EB%8A%94%20%EA%B2%83%EC%9E%85%EB%8B%88%EB%8B%A4

### Tensorflow dataset
1. https://soundprovider.tistory.com/entry/Tensorflow-tfds%EB%A5%BC-%ED%99%9C%EC%9A%A9%ED%95%9C-custom-dataset-%EC%83%9D%EC%84%B1 

2. https://www.tensorflow.org/datasets/add_dataset#dataset_example